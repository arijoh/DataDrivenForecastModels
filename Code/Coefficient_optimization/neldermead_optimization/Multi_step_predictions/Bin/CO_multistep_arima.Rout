
R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> 
> 
> 
> cores <- as.numeric(Sys.getenv('LSB_DJOB_NUMPROC'))
> setwd("/zhome/6e/9/133731/Desktop/Thesis/Thesis")
> #cores = parallel::detectCores()
> 
> 
> 
> meta_optim=function(orders, external_regressor){
+ 
+   compute_arime_mse=function(pars,order){
+     multistepARIMA <- function(order, coefficients, external_regressor){
+       
+       exit <- function() {
+         .Internal(.invokeRestart(list(NULL, NULL), NULL))
+       }
+       
+       step1 <- function(ts, step1res){
+         
+         ######## If mean is not zero
+         if (mean(ts, na.rm = T) > tol){
+           ts <- ts - mean(ts, na.rm = TRUE)
+         }
+         X <- matrix(ncol = (p + q + 1 + length(REG)), ## Number of terms
+                     nrow = length(observed)
+         )
+         if (external_regressor == FALSE){
+           if ((p > 0) & (q > 0)){
+             for (i in ((r+nstep+d):length(observed))){ ## i is the n we are predicting, we need to add d
+               y <- ts[(i - 1 - d + d):(i - p - d + d)]
+               eps <- step1res[(i - 1):(i-q)]
+               X[i, ] <- c(1, y, eps) #X[(i-r-d), ]
+             }
+           } else if ((p > 0) & (q == 0)){
+             for (i in ((r+nstep+d):(length(observed)))){ ## i is the n we are predicting, we need to add d
+               y <- ts[(i - 1 - d + d):(i - p - d + d)]
+               X[i, ] <- c(1, y)
+             }
+           } else if ((p == 0) & (q > 0)){
+             for (i in ((r+nstep+d):(length(observed)))){ ## i is the n we are predicting, we need to add d
+               eps <- step1res[(i - 1 + d + d):(i-q + d + d)]
+               X[i, ] <- c(1, eps)
+             }
+           } else{
+             X[] <- 1
+           }
+         } else {
+           #### With regressor
+           if ((p > 0) & (q > 0)){
+             for (i in ((r+nstep+d):length(observed))){ ## i is the n we are predicting, we need to add d
+               y <- ts[(i - 1 - d + d):(i - p - d + d)]
+               eps <- step1res[(i - 1):(i-q)]
+               X[i, ] <- c(1, y, eps, Regressor[i])
+             }
+           } else if ((p > 0) & (q == 0)){
+             for (i in ((r+nstep+d):(length(observed)))){ ## i is the n we are predicting, we need to add d
+               y <- ts[(i - 1 - d + d):(i - p - d + d)]
+               X[i, ] <- c(1, y, Regressor[i])
+             }
+           } else if ((p == 0) & (q > 0)){
+             for (i in ((r+nstep+d):(length(observed)))){ ## i is the n we are predicting, we need to add d
+               eps <- step1res[(i - 1 + d + d):(i-q + d + d)]
+               X[i, ] <- c(1, eps, Regressor[i])
+             }
+           } else{
+             X[] <- 1
+           }
+           
+           
+         }
+         
+         
+         pred <- X %*% delta
+         
+         if (d > 0){
+           pred_ <- pred
+           pred <- pred + lag(observed, 1)
+           res <- observed - pred
+         } else{
+           res <- observed - pred
+           pred_ <- NULL
+         }
+         
+         return(list(pred, 
+                     res,
+                     X,
+                     pred_))
+       }
+       step_n <- function(priorPred, priorRes, nstep, X){## might not need ts or step1res
+         
+         ######## If mean is not zero
+         if (abs(mean(priorPred, na.rm = TRUE)) > tol){
+           priorPred <- priorPred - mean(priorPred, na.rm = TRUE)
+         }
+         
+         if (nstep == 2){
+           priorPred <-append(NA, priorPred[(1):(length(priorPred)-1)])
+           priorRes <- rep(0, length(priorPred)) 
+           temp <- nstep + r - 1 + d
+           priorRes[1:temp] <- NA
+           
+           if (p > 0){
+             X[,2] <- priorPred
+             X[temp, ] <- NA 
+           }
+           if (q > 0){
+             X[,2+p] <- priorRes
+           }
+           
+           X[temp, ] <- NA
+         }
+         
+         else if (nstep > 2){
+           
+           if ((p > 0) && (q > 0)){
+             P <- as.matrix(X[,(2:(p+1))])
+             Q <- as.matrix(X[,((p+2):(ncol(X)-length(REG)))])
+             
+             P <- rbind(rep(NA, ncol(P)), P)
+             Q <- rbind(rep(NA, ncol(Q)), Q)
+           } else if ((p == 0) && (q > 0)){
+             P <- NULL
+             Q <- as.matrix(X[,((p+2):(ncol(X)-length(REG)))])
+             Q <- rbind(rep(NA, ncol(Q)), Q)
+           } else if ((p > 0) && (q == 0)){
+             P <- as.matrix(X[,(2:(p+1))])        
+             P <- rbind(rep(NA, ncol(P)), P)
+             Q <- NULL
+           }
+           
+           
+           if (p >= 1){
+             priorPred <- priorPred[1:(length(priorPred)-1)]
+             priorPred <- append(NA, priorPred)
+             if (p == 1){
+               P1 <- NULL
+               P2 <- NULL
+             } else if (nstep >= p){
+               P1 <- as.matrix(P[(1:(nrow(P)-1)),(1:(p-1))]) 
+               P2 <- NULL
+             } else {
+               P1 <- as.matrix(P[(1:(nrow(P)-1)),(1:(nstep-2))]) ## This will be shifted
+               P2 <- as.matrix(P[2:nrow(P), (nstep-2+1):(ncol(P)-1)])
+             }
+           } else{
+             P1 <- NULL
+             P2 <- NULL
+             priorPred <- NULL
+           }
+           
+           if (q >= 1){
+             priorRes <- rep(0, nrow(X))#priorRes[1:(length(priorRes)-1)]
+             priorRes[1:(r+nstep-1+d)] <- NA
+             if (q == 1){
+               Q1 <- NULL
+               Q2 <- NULL
+             } else if (nstep >= q){
+               Q1 <- as.matrix(Q[(1:(nrow(Q)-1)),1:(q - 1)]) ## This will be shifted
+               Q2 <- NULL
+             } else{
+               Q1 <- as.matrix(Q[(1:(nrow(Q)-1)),(1:(nstep-2))]) ## This will be shifted
+               Q2 <- as.matrix(Q[2:nrow(Q), (nstep-2+1):(ncol(Q)-1)])
+             } 
+           } else{
+             Q1 <- NULL
+             Q2 <- NULL
+             priorRes <- NULL
+           }
+           
+           
+           X <- cbind(1,
+                      priorPred,
+                      P1,
+                      P2,
+                      priorRes,
+                      Q1,
+                      Q2,
+                      Regressor)
+           
+           X[1:(nstep+r-1+d),] <- NA
+           
+         }
+         
+         pred <- X %*% delta
+         
+         if (d > 0){
+           pred_ <- pred
+           pred <- pred + lag(observed,1)
+           res <- observed-pred
+         } else{
+           res <- observed-pred
+           pred_ <- NULL
+         }
+         
+         return(list(pred, 
+                     res,
+                     X, 
+                     pred_))
+       }
+       
+       
+       
+       tol <- 1e-4
+       p <- order[1]
+       q <- order[3]
+       d <- order[2]
+       r <- max(p, q)
+       if(external_regressor == FALSE){
+         model <- arima(x = ts, order = order, fixed = coefficients)
+         REG <- NULL
+         Regressor <- NULL
+       }else{
+         model <- arima(x = ts,order = order, fixed = coefficients, xreg = Regressor)
+         REG <- coefficients[length(coefficients)]
+         Regressor <- Regressor
+       }
+       step1res <- residuals(model)
+       
+       if ((p > 0) && (q > 0)){
+         AR <- coefficients[1:p]
+         MA <- coefficients[(p+1) : (p  + q)]
+       }else if ((p == 0) && (q > 0)){
+         AR <- NULL
+         MA <- coefficients[(p+1) : (q  + p)]
+       }else if ((p > 0) && (q == 0)){
+         AR <- coefficients[1:p]
+         MA <- NULL
+       }else{
+         AR <- NULL
+         MA <- NULL
+         print("No parameters to optimize for")
+         exit()
+       }
+       if (d > 0){  
+         I <-  0
+       } else{
+         I <- as.numeric(coefficients[(p + q + 1)])
+       }
+       
+       delta <- as.matrix(c(interc = I, AR, MA, REG))
+       
+       ## 1-step prediction and getting treated time series and delta
+       nstep <- 1
+       output <- step1(ts, step1res)
+       pred <- unlist(output[1])
+       res <- unlist(output[2])
+       X <- matrix(unlist(output[3]),   ncol = (p + q + 1 + length(REG)), nrow = length(ts))
+       if (d > 0){ pred_ <- unlist(output[4]) } ## pred_ is used for iteration when d > 0
+       res_list<- list()
+       res_list[[1]] <- res
+       pred_list <- list()
+       pred_list[[1]] <- pred
+       
+       for (i in 2:10){
+         nstep <- i
+         if (d > 0){ 
+           output <- step_n(priorPred = pred_, priorRes = res, nstep = nstep, X = X) 
+           pred_ <- unlist(output[4])
+         } else{ 
+           output <- step_n(priorPred = pred, priorRes = res, nstep = nstep, X = X) 
+         }
+         pred <- unlist(output[1])
+         res <- unlist(output[2])
+         X <- matrix(unlist(output[3]),   ncol = (p + q + 1 + length(REG)), nrow = length(observed))
+         
+         res_list[[i]] <- res
+         pred_list[[i]] <- pred
+       }
+       
+       return(list(residuals = res_list, predictions = pred_list))
+     }
+     output <- multistepARIMA(order = order, coefficients = pars, external_regressor = external_regressor)
+     x <- matrix(unlist(output$residuals), ncol = length(unlist(output$residuals))[1], nrow = 10)
+     k <- 10
+     under <- 0
+     for (j in 1:k){ under <- under + k - j + 1 }
+     e <- vector()
+     
+     
+     for (i in 1:19781){
+       upper <- 0
+       for (j in 1:k){
+         upper <- upper + ((k - j + 1) * x[j,i] )
+       }
+       e[i] <- upper
+     }
+     
+     SC <-  mean(e[wwIndex == 1]^2, na.rm = T) #mean could provide better results, not really sure why..
+     return(SC) 
+   }
+   
+   templist <- list()
+   
+   n <- orders[1]+orders[3]
+   
+   if (external_regressor == TRUE){
+     n = n + 1
+   }
+   
+   if (orders[2] == 0){n <- n+1}
+   
+   if (n>0){
+     startpars=  vector(length = n)
+     counter <- 1
+     max_counter <- 50
+     while (counter <= max_counter){
+       
+       startpars <- rnorm(n = n)
+       results = try(optim(par = startpars, fn = compute_arime_mse, order=orders, method = "L-BFGS-B"), silent = TRUE) #
+       if ((is(results, 'try-error')) || (results$convergence != 0))
+       {
+         counter = counter + 1
+       } else{
+         break;
+       }
+     }
+     if (counter >= max_counter){
+       templist[[1]] <- orders
+       templist[[2]] = "500 tries: failed to converge"
+     } else{
+       if (external_regressor == TRUE){
+         model=arima(x=ts, order = orders, fixed = results$par, xreg = Regressor)
+       } else{
+         model=arima(x=ts, order = orders)
+       }
+       
+       templist <- list(order = orders, parameters = results$par, value = results$value, iterations = results$counts, convergence = results$convergence, message = results$message, loglikelihood = model$loglik, AIC = model$aic)
+     }
+   } else{      
+     templist[[1]] <- orders
+     templist[[2]] <- "No parameters to optimize for"
+   }
+   return(templist)
+ }
> 
> 
> 
> ##################### Reading in data ##################### 
> s1_training <-  read.csv("Data/Training data/s1_training.txt", header = TRUE, sep = "\t")
> s1 <- s1_training$Value
> s2_training <-  read.csv("Data/Training data/s2_training.txt", header = TRUE, sep = "\t")
> s2 <- s2_training$Value
> s1_wwIndex <- read.csv("Data/Training data/s1_WW_training.txt", header = TRUE, sep = "\t")
> s2_wwIndex <- read.csv("Data/Training data/s2_WW_training.txt", header = TRUE, sep = "\t")
> 
> 
> ##################### Parameters ##################### 
> MAX <- 8
> x <- expand.grid(0:MAX, 0:2, 0:MAX)
> colnames(x) <- c("p", "d", "q")
> 
> ##################### Optimization for Dammning (station 1) ##################### 
> 
> ## training data and observed data are the same but ts is modified within functions before calculating the residuals
> ts <- s1 
> observed <- s1
> wwIndex <- s1_wwIndex$Flag
> 
> 
> system.time(
+   CO_s1 <- parallel::mclapply(1:nrow(x), function(i){
+     temp <- as.matrix(x[i,])
+     temp <- c(temp[1], temp[2], temp[3])
+     start_time <- Sys.time()
+     results <- meta_optim(temp, external_regressor = FALSE)
+     end_time <- Sys.time()
+     time_taken <- end_time - start_time
+     print(paste("Order: ", "(", temp[1], ", ", temp[2], ", ", temp[3], ")", " takes ", signif(time_taken, 4), " seconds to optimize", sep = ""))
+   }, mc.cores = cores, mc.allow.recursive = TRUE, mc.preschedule=FALSE)
+ )
[1] "Order: (0, 1, 0) takes 0.0001435 seconds to optimize"
[1] "No parameters to optimize for"
[1] "Order: (1, 1, 0) takes 14.51 seconds to optimize"
[1] "Order: (2, 1, 0) takes 35.89 seconds to optimize"
[1] "Order: (1, 0, 0) takes 1.488 seconds to optimize"
[1] "Order: (3, 1, 0) takes 1.856 seconds to optimize"
[1] "Order: (4, 1, 0) takes 2.023 seconds to optimize"
[1] "Order: (2, 0, 0) takes 7.098 seconds to optimize"
[1] "Order: (5, 1, 0) takes 8.882 seconds to optimize"
[1] "Order: (0, 2, 0) takes 7.725e-05 seconds to optimize"
[1] "Order: (1, 2, 0) takes 13.31 seconds to optimize"
[1] "Order: (3, 0, 0) takes 10.78 seconds to optimize"
[1] "Order: (2, 2, 0) takes 34.7 seconds to optimize"
[1] "Order: (7, 1, 0) takes 9.426 seconds to optimize"
[1] "Order: (3, 2, 0) takes 1.765 seconds to optimize"
[1] "Order: (4, 2, 0) takes 3.264 seconds to optimize"
[1] "Order: (5, 2, 0) takes 4.153 seconds to optimize"
[1] "Order: (6, 1, 0) takes 14.29 seconds to optimize"
[1] "Order: (0, 0, 1) takes 2.763 seconds to optimize"
[1] "Order: (6, 2, 0) takes 9.679 seconds to optimize"
[1] "Order: (1, 0, 1) takes 5.293 seconds to optimize"
[1] "Order: (8, 1, 0) takes 18.1 seconds to optimize"
[1] "Order: (7, 2, 0) takes 11.88 seconds to optimize"
[1] "Order: (4, 0, 0) takes 26.65 seconds to optimize"
[1] "Order: (5, 0, 0) takes 28.14 seconds to optimize"
[1] "Order: (8, 2, 0) takes 13.7 seconds to optimize"
[1] "Order: (2, 0, 1) takes 15.11 seconds to optimize"
[1] "Order: (3, 0, 1) takes 13.68 seconds to optimize"
[1] "Order: (0, 1, 1) takes 2.504 seconds to optimize"
[1] "Order: (1, 1, 1) takes 3.81 seconds to optimize"
[1] "Order: (4, 0, 1) takes 16.91 seconds to optimize"
[1] "Order: (2, 1, 1) takes 7.551 seconds to optimize"
[1] "Order: (3, 1, 1) takes 13.22 seconds to optimize"
[1] "Order: (8, 0, 1) takes 30.77 seconds to optimize"
[1] "Order: (6, 0, 1) takes 35 seconds to optimize"
[1] "Order: (5, 0, 1) takes 36.86 seconds to optimize"
[1] "Order: (0, 2, 1) takes 21.89 seconds to optimize"
[1] "Order: (1, 2, 1) takes 1.771 seconds to optimize"
[1] "Order: (2, 2, 1) takes 3.8 seconds to optimize"
[1] "Order: (7, 1, 1) takes 11.95 seconds to optimize"
[1] "Order: (4, 1, 1) takes 39.23 seconds to optimize"
[1] "Order: (6, 0, 0) takes 1.357 seconds to optimize"
[1] "Order: (5, 1, 1) takes 35.95 seconds to optimize"
[1] "Order: (3, 2, 1) takes 15.83 seconds to optimize"
[1] "Order: (8, 1, 1) takes 55.26 seconds to optimize"
[1] "Order: (5, 2, 1) takes 37.1 seconds to optimize"
[1] "Order: (4, 2, 1) takes 48.58 seconds to optimize"
[1] "Order: (0, 0, 2) takes 5.076 seconds to optimize"
[1] "Order: (2, 0, 2) takes 5.448 seconds to optimize"
[1] "Order: (3, 0, 2) takes 10.61 seconds to optimize"
[1] "Order: (1, 0, 2) takes 15.98 seconds to optimize"
[1] "Order: (5, 0, 2) takes 29.79 seconds to optimize"
[1] "Order: (6, 1, 1) takes 2.046 seconds to optimize"
[1] "Order: (7, 2, 1) takes 1.586 seconds to optimize"
[1] "Order: (0, 1, 2) takes 1.033 seconds to optimize"
[1] "Order: (1, 1, 2) takes 4.06 seconds to optimize"
[1] "Order: (2, 1, 2) takes 5.291 seconds to optimize"
[1] "Order: (6, 0, 2) takes 56.77 seconds to optimize"
[1] "Order: (4, 0, 2) takes 1.233 seconds to optimize"
[1] "Order: (3, 1, 2) takes 12.4 seconds to optimize"
[1] "Order: (4, 1, 2) takes 17.76 seconds to optimize"
[1] "Order: (8, 0, 2) takes 51.51 seconds to optimize"
[1] "Order: (8, 2, 1) takes 2.568 seconds to optimize"
[1] "Order: (0, 2, 2) takes 4.134 seconds to optimize"
[1] "Order: (5, 1, 2) takes 43.96 seconds to optimize"
[1] "Order: (1, 2, 2) takes 2.636 seconds to optimize"
[1] "Order: (6, 1, 2) takes 47.23 seconds to optimize"
[1] "Order: (6, 2, 1) takes 2.879 seconds to optimize"
[1] "Order: (7, 0, 0) takes 4.3 seconds to optimize"
[1] "Order: (2, 2, 2) takes 13.69 seconds to optimize"
[1] "Order: (6, 2, 2) takes 7.363 seconds to optimize"
[1] "Order: (3, 2, 2) takes 26.63 seconds to optimize"
[1] "Order: (8, 0, 0) takes 4.597 seconds to optimize"
[1] "Order: (7, 0, 2) takes 1.931 seconds to optimize"
[1] "Order: (0, 0, 3) takes 8.208 seconds to optimize"
[1] "Order: (7, 2, 2) takes 31.5 seconds to optimize"
[1] "Order: (8, 2, 2) takes 25.55 seconds to optimize"
[1] "Order: (6, 0, 3) takes 10.82 seconds to optimize"
[1] "Order: (4, 0, 3) takes 16.6 seconds to optimize"
[1] "Order: (0, 1, 3) takes 1.351 seconds to optimize"
[1] "Order: (1, 1, 3) takes 5.973 seconds to optimize"
[1] "Order: (8, 0, 3) takes 14.73 seconds to optimize"
[1] "Order: (2, 1, 3) takes 3.28 seconds to optimize"
[1] "Order: (1, 0, 3) takes 44.69 seconds to optimize"
[1] "Order: (3, 1, 3) takes 17.17 seconds to optimize"
[1] "Order: (8, 1, 2) takes 1.827 seconds to optimize"
[1] "Order: (5, 0, 3) takes 52.06 seconds to optimize"
[1] "Order: (4, 2, 2) takes 1.585 seconds to optimize"
[1] "Order: (0, 2, 3) takes 1.687 seconds to optimize"
[1] "Order: (4, 1, 3) takes 28.45 seconds to optimize"
[1] "Order: (7, 1, 3) takes 12.29 seconds to optimize"
[1] "Order: (1, 2, 3) takes 7.988 seconds to optimize"
[1] "Order: (7, 1, 2) takes 2.413 seconds to optimize"
[1] "Order: (5, 1, 3) takes 42.13 seconds to optimize"
[1] "Order: (5, 2, 2) takes 1.836 seconds to optimize"
[1] "Order: (5, 2, 3) takes 13.42 seconds to optimize"
[1] "Order: (2, 2, 3) takes 22.65 seconds to optimize"
[1] "Order: (7, 2, 3) takes 11.32 seconds to optimize"
[1] "Order: (6, 1, 3) takes 45.51 seconds to optimize"
[1] "Order: (3, 2, 3) takes 30.58 seconds to optimize"
[1] "Order: (8, 1, 3) takes 44.8 seconds to optimize"
[1] "Order: (3, 0, 4) takes 8.551 seconds to optimize"
[1] "Order: (0, 0, 4) takes 21.33 seconds to optimize"
[1] "Order: (6, 0, 4) takes 24.02 seconds to optimize"
[1] "Order: (5, 0, 4) takes 28.6 seconds to optimize"
[1] "Order: (4, 2, 3) takes 1.121 seconds to optimize"
[1] "Order: (0, 1, 4) takes 2.263 seconds to optimize"
[1] "Order: (1, 1, 4) takes 7.165 seconds to optimize"
[1] "Order: (2, 0, 4) takes 49.04 seconds to optimize"
[1] "Order: (1, 0, 4) takes 56.44 seconds to optimize"
[1] "Order: (7, 0, 3) takes 2.368 seconds to optimize"
[1] "Order: (8, 0, 4) takes 33.04 seconds to optimize"
[1] "Order: (3, 1, 4) takes 22 seconds to optimize"
[1] "Order: (2, 1, 4) takes 49.79 seconds to optimize"
[1] "Order: (0, 2, 4) takes 3.372 seconds to optimize"
[1] "Order: (1, 2, 4) takes 9.95 seconds to optimize"
[1] "Order: (2, 2, 4) takes 15.13 seconds to optimize"
[1] "Order: (8, 2, 3) takes 2.284 seconds to optimize"
[1] "Order: (6, 2, 3) takes 2.547 seconds to optimize"
[1] "Order: (8, 1, 4) takes 1.108 seconds to optimize"
[1] "Order: (4, 1, 4) takes 1.675 seconds to optimize"
[1] "Order: (3, 2, 4) takes 32.09 seconds to optimize"
[1] "Order: (5, 1, 4) takes 2.197 seconds to optimize"
[1] "Order: (0, 0, 5) takes 22.84 seconds to optimize"
[1] "Order: (5, 2, 4) takes 1.643 seconds to optimize"
[1] "Order: (1, 0, 5) takes 28.41 seconds to optimize"
[1] "Order: (6, 1, 4) takes 3.116 seconds to optimize"
[1] "Order: (6, 2, 4) takes 2.416 seconds to optimize"
[1] "Order: (4, 2, 4) takes 2.769 seconds to optimize"
[1] "Order: (7, 0, 5) takes 35.09 seconds to optimize"
[1] "Order: (0, 1, 5) takes 5.028 seconds to optimize"
There were 50 or more warnings (use warnings() to see the first 50)
Warning message:
In log(s2) : NaNs produced
There were 50 or more warnings (use warnings() to see the first 50)
There were 50 or more warnings (use warnings() to see the first 50)
Warning message:
Warning message:
There were 50 or more warnings (use warnings() to see the first 50)In log(s2) :
 NaNs produced
In log(s2) : NaNs produced
Timing stopped at: 3.823e+05 779.2 4.32e+04
Execution halted
